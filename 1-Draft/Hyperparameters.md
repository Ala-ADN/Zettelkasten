### Definition
Hyperparameters are configuration variables that are set before training
The goal of hyperparameter tuning is to balance the bias-variance tradeoff
- **Bias** is the divergence between a modelâ€™s predictions and reality; underfitted models fail to discern key relationships between datapoints
- **Variance** is the sensitivity of a model to new data; overfitted models are too complex and fail to accommodate new datapoints
=>Models with low bias are accurate, while models with low variance are consistent