1. **List the Data You Need and How Much You Need**
2. **Find and Document Where You Can Get That Data**
   - [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/)
   - [Kaggle Datasets](https://www.kaggle.com/datasets)
   - [Amazon’s AWS Datasets](https://registry.opendata.aws/)
   - [HuggingFace](https://huggingface.co/datasets)
   - [Data Portals](https://www.data.gov/)
   - [OpenDataMonitor](https://www.opendatamonitor.eu/)
   - [Quandl](https://data.nasdaq.com/search)
   - [Wikipedia’s List of Machine Learning Datasets](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research)
   - [Quora.com](https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public)
   - [The Datasets Subreddit](https://www.reddit.com/r/datasets/)
3. **Check Legal Obligations, and Get Authorization if Necessary**
4. **Get Access Authorizations**
5. **Convert the Data to a Format You Can Easily Manipulate**
- [[Pandas]]
7. **Ensure Sensitive Information is Deleted or Protected**
8. **Check the Size and Type of Data (Time Series, Sample, Geographical...)**